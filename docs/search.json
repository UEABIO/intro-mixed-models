[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"Data often complex messy.can different grouping factors like collect data, etc. Sample sizes may also leave something desired, especially try fit complicated models many parameters. top , data points might truly independent. instance, might structure data.mixed models developed, deal messy data allow us use data, even low sample sizes, structured data many covariates fit. top , mixed models allow us save degrees freedom compared running standard linear models! Sounds good.cover basics linear mixed models, use responsibly interepret findings effectively.trying “extend” linear model, fear : generalised linear mixed effects models, .","code":""},{"path":"index.html","id":"terminology","chapter":"Overview","heading":"0.1 Terminology","text":"Mixed-effects models sometime referred hierarchical models, multi-level models, random effects models, mixed-models. Regardless confusing vocabulary, ’s worth knowing terms may used mean similar models.Random effects important part mixed-effects models. Random effects capture variations come grouping clustering data. used mixed models, combine fixed effects (relationships variables) random effects. approach helps us account correlations dependencies within groups, making models realistic.nature, often see hierarchical structures, streams within watershed species within family. Random effects can useful situations others observations tend clustered. using random effects, can improve ability model system accurately.main purpose applying random effects mixed models capture realistic patterns uncertainties data. example, can account correlations arise multiple observations within group observations lack complete independence.sum , random effects mixed models help us deal situations observations independent. allow us capture complexities dependencies within groups, improving accuracy statistical models.","code":""},{"path":"index.html","id":"variance","chapter":"Overview","heading":"0.1.1 Variance","text":"understand mixed- random effects models, need understand random effects understand random effects, need understand variance.Variance statistical measure quantifies spread dispersion set data points. provides measure much values dataset deviate mean.calculate variance linear model (ordinary least squares), first obtain residuals, differences observed response values predicted values. , square residual eliminate negative signs calculate sum squared residuals. Finally, divide sum degrees freedom, total number observations minus number estimated coefficients model.o estimate variance components linear mixed model, likelihood-based methods maximum likelihood estimation (MLE) restricted maximum likelihood estimation (REML) commonly used. methods optimize likelihood function adjusting model parameters, including variance components, find values best fit observed data.","code":""},{"path":"foundations-of-mixed-modelling.html","id":"foundations-of-mixed-modelling","chapter":"1 Foundations of Mixed Modelling","heading":"1 Foundations of Mixed Modelling","text":"","code":""},{"path":"foundations-of-mixed-modelling.html","id":"what-is-a-mixed-model","chapter":"1 Foundations of Mixed Modelling","heading":"1.1 What is a mixed model?","text":"Mixed models (also known linear mixed models hierarchical linear models) statistical tests build simpler tests regression, t-tests ANOVA. tests special cases general linear model; fit straight line data explain variance systematic way.key difference linear mixed-effects model inclusion random effects - variables observations grouped subcategories systematically affect outcome - account important structure data.mixed-effects model can used many situations instead one straightforward tests structure may important. main advantages approach :mixed-effects models account variancemixed-effects models incorporate group even individual-level differencesmixed-effects models cope well missing data, unequal group sizes repeated measurements","code":""},{"path":"foundations-of-mixed-modelling.html","id":"fixed-vs-random-effects","chapter":"1 Foundations of Mixed Modelling","heading":"1.2 Fixed vs Random effects","text":"Fixed effects random effects terms commonly used mixed modeling, statistical framework combines order analyze data.mixed modeling, fixed effects used estimate overall relationship predictors response variable, random effects account within-group variability allow modeling individual differences group-specific effects.hierarchical structure data refers data organization observations nested within higher-level groups clusters. example, students nested within classrooms, patients nested within hospitals, employees nested within companies. hierarchical structure introduces dependencies correlations within data, observations within group tend similar observations different groups.need mixed models arises want account dependencies properly model variability different levels hierarchy. Traditional regression models, ordinary least squares (OLS), assume observations independent . However, working hierarchical data, assumption violated, ignoring hierarchical structure can lead biased inefficient estimates, incorrect standard errors, misleading inference.including random effects, mixed models allow estimation within-group -group variability. provide flexible framework modeling individual group-specific effects can capture heterogeneity within groups. Additionally, mixed models can handle unbalanced incomplete data, groups may different numbers observations.","code":""},{"path":"foundations-of-mixed-modelling.html","id":"fixed-effects","chapter":"1 Foundations of Mixed Modelling","heading":"1.2.1 Fixed effects","text":"broad terms, fixed effects variables expect affect dependent/response variable: ’re call explanatory variables standard linear regression.Fixed effects common random effects, least use. Fixed effects estimate different levels relationship assumed levels. example, model dependent variable body length fixed effect fish sex, get estimate mean body length males estimate females separately.can consider terms simple linear model, estimated intercept expected value outcome \\(y\\) predictor \\(x\\) value 0. estimated slope expected change \\(y\\) single unit change \\(x\\). parameters \"fixed\", meaning individual population expected value intercept slope.difference expected value true value called \"residual error\".\\[Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i\\]","code":""},{"path":"foundations-of-mixed-modelling.html","id":"examples","chapter":"1 Foundations of Mixed Modelling","heading":"1.2.1.1 Examples:","text":"Medical Research: clinical trial studying effectiveness different medications treating specific condition, fixed effects include categorical variables treatment group (e.g., medication , medication B, placebo) dosage level (e.g., low, medium, high). fixed effects capture systematic differences response variable (e.g., symptom improvement) due specific treatment received.Medical Research: clinical trial studying effectiveness different medications treating specific condition, fixed effects include categorical variables treatment group (e.g., medication , medication B, placebo) dosage level (e.g., low, medium, high). fixed effects capture systematic differences response variable (e.g., symptom improvement) due specific treatment received.Education Research: Suppose study examines impact teaching methods student performance different schools. fixed effects case might include variables school type (e.g., public, private), curriculum approach (e.g., traditional, progressive), classroom size. fixed effects help explain differences student achievement across schools, accounting systematic effects factors.Education Research: Suppose study examines impact teaching methods student performance different schools. fixed effects case might include variables school type (e.g., public, private), curriculum approach (e.g., traditional, progressive), classroom size. fixed effects help explain differences student achievement across schools, accounting systematic effects factors.Environmental Science: Imagine study investigating factors influencing bird species richness across different habitats. fixed effects context include variables habitat type (e.g., forest, grassland, wetland), habitat disturbance level (e.g., low, medium, high), geographical region. fixed effects capture systematic variations bird species richness associated specific habitat characteristics.Environmental Science: Imagine study investigating factors influencing bird species richness across different habitats. fixed effects context include variables habitat type (e.g., forest, grassland, wetland), habitat disturbance level (e.g., low, medium, high), geographical region. fixed effects capture systematic variations bird species richness associated specific habitat characteristics.Fixed effects default effects learn begin understand statistical concepts, fixed effects default effects functions like lm() aov().","code":""},{"path":"foundations-of-mixed-modelling.html","id":"random-effects","chapter":"1 Foundations of Mixed Modelling","heading":"1.2.2 Random effects","text":"Random effects less commonly used perhaps widely encountered nature. level can considered random variable underlying process distribution random effect.random effect parameter allowed vary across groups individuals. Random effects take single fixed value, rather follow distribution (usually normal distribution). Random effects can added model account variation around intercept slope. individual group gets estimated random effect, representing adjustment mean.random effects usually grouping factors trying control. always categorical, can’t force R treat continuous variable random effect. lot time specifically interested impact response variable, know might influencing patterns see.","code":""},{"path":"foundations-of-mixed-modelling.html","id":"examples-1","chapter":"1 Foundations of Mixed Modelling","heading":"1.2.2.1 Examples:","text":"Longitudinal Health Study: Consider study tracking blood pressure individuals multiple time points. case, random effect can included account individual-specific variation blood pressure. individual's blood pressure measurements time treated repeated measures within individual, random effect capture variability individuals explained fixed effects. random effect allows modeling inherent individual differences blood pressure levels.Longitudinal Health Study: Consider study tracking blood pressure individuals multiple time points. case, random effect can included account individual-specific variation blood pressure. individual's blood pressure measurements time treated repeated measures within individual, random effect capture variability individuals explained fixed effects. random effect allows modeling inherent individual differences blood pressure levels.Social Network Analysis: Suppose study examines influence peer groups adolescent behavior. study may collect data individual behaviors within schools, students nested within classrooms. scenario, random effect can incorporated classroom level account shared social environment within classroom. random effect captures variability behavior among classrooms accounted fixed effects, enabling study analyze effects individual-level classroom-level factors simultaneously.Social Network Analysis: Suppose study examines influence peer groups adolescent behavior. study may collect data individual behaviors within schools, students nested within classrooms. scenario, random effect can incorporated classroom level account shared social environment within classroom. random effect captures variability behavior among classrooms accounted fixed effects, enabling study analyze effects individual-level classroom-level factors simultaneously.Ecological Study: Imagine research project investigating effect environmental factors species abundance different study sites. study sites may geographically dispersed, random effect can included account variation study sites. random effect captures unexplained heterogeneity species abundance across different sites, allowing examination effects environmental variables accounting site-specific differences.Ecological Study: Imagine research project investigating effect environmental factors species abundance different study sites. study sites may geographically dispersed, random effect can included account variation study sites. random effect captures unexplained heterogeneity species abundance across different sites, allowing examination effects environmental variables accounting site-specific differences.random effect \\(U_i\\) often assumed follow normal distribution mean zero variance estimated model fitting process.\\[Y_i = β_0 + U_j + ε_i\\]\nbook “Data analysis using regression \nmultilevel/hierarchical models” (Gelman & Hill (2006)). authors examined five\ndefinitions fixed random effects found consistent\nagreement.\n\n\nFixed effects constant across individuals, random effects\nvary. example, growth study, model random intercepts a_i\nfixed slope b corresponds parallel lines different\nindividuals , model y_it = a_i + b t thus distinguish \nfixed random coefficients.\n\n\nFixed effects constant across individuals, random effects\nvary. example, growth study, model random intercepts a_i\nfixed slope b corresponds parallel lines different\nindividuals , model y_it = a_i + b t thus distinguish \nfixed random coefficients.\n\n\nEffects fixed interesting random\ninterest underlying population.\n\n\nEffects fixed interesting random\ninterest underlying population.\n\n\n“sample exhausts population, corresponding\nvariable fixed; sample small (.e., negligible) part \npopulation corresponding variable random.”\n\n\n“sample exhausts population, corresponding\nvariable fixed; sample small (.e., negligible) part \npopulation corresponding variable random.”\n\n\n“effect assumed realized value random\nvariable, called random effect.”\n\n\n“effect assumed realized value random\nvariable, called random effect.”\n\n\nFixed effects estimated using least squares (, \ngenerally, maximum likelihood) random effects estimated \nshrinkage.\n\n\nFixed effects estimated using least squares (, \ngenerally, maximum likelihood) random effects estimated \nshrinkage.\n\nThus turns fixed random effects born made. \nmust make decision treat variable fixed random \nparticular analysis.\ndetermining fixed random effect study, consider trying ? trying make predictions ? just variation (.k.“noise”) need control ?\nrandom effects:\n\nNote golden rule generally want random\neffect least five levels. , instance, wanted \ncontrol effects fish sex body length, fit sex (\ntwo level factor: male female) fixed, random, effect.\n\n, put simply, estimating variance data points\nimprecise. Mathematically , wouldn’t lot\nconfidence . two three levels, model\nstruggle partition variance - give output,\nnecessarily one can trust.\n\nFinally, keep mind name random doesn’t much \nmathematical randomness. Yes, ’s confusing. Just think \ngrouping variables now. Strictly speaking ’s \nmaking models representative questions getting better\nestimates. Hopefully, next examples help make sense \n’re used.\n\n’s firm rule minimum number factor levels\nrandom effect really can use factor \ntwo levels. However commonly reported may want\nfive factor levels random effect order really\nbenefit random effect can (though argue even\n, 10 levels). Another case may want random\neffect don’t want factor levels inform \ndon’t assume factor levels come common\ndistribution. noted , male female factor \ntwo levels oftentimes want male female information\nestimated separately ’re necessarily assuming males \nfemales come population sexes infinite\nnumber ’re interested average.\n","code":""},{"path":"foundations-of-mixed-modelling.html","id":"why-use-mixed-models","chapter":"1 Foundations of Mixed Modelling","heading":"1.3 Why use mixed models?","text":"provided code generates dataset suitable testing mixed models. break code annotate step:section creates data frame called rand_eff containing random effects. consists five levels grouping variable (group), level, generates random effects (b0 b1) using rnorm function.section creates main dataset (data) testing mixed models. uses expand.grid create combination levels grouping variable (group) observation variable (obs). performs left join rand_eff data frame, matching group variable incorporate random effects group.code continues mutate dataset adding additional variables:x random predictor variable generated using runif values 0 10.x random predictor variable generated using runif values 0 10.B0 B1 represent fixed effects intercept slope predetermined values 20 2, respectively.B0 B1 represent fixed effects intercept slope predetermined values 20 2, respectively.E represents error term, generated using rnorm mean 0 standard deviation 10.E represents error term, generated using rnorm mean 0 standard deviation 10.Finally, y created response variable using linear model equation includes fixed effects (B0 B1), random effects (b0 b1), predictor variable (x), error term (E).Finally, y created response variable using linear model equation includes fixed effects (B0 B1), random effects (b0 b1), predictor variable (x), error term (E).section creates additional dataset (data.1) specific group (group = 5) smaller number observations (obs = 30) testing purposes. appended original dataset, see effect smaller group within random effects discuss partial pooling shrinkage later .Now three variables consider models: x, y group (five levels).Now suitable simulated dataset, start modelling!","code":"\ndata <- expand.grid(group = as.factor(seq(1:10)), \n                    obs = as.factor(seq(1:100))) %>%\n  left_join(rand_eff,\n            by = \"group\") %>%\n  mutate(x = runif(n = nrow(.), 0, 10),\n         B0 = 20,\n         B1 = 2,\n         E = rnorm(n = nrow(.), 0, 10)) %>%\n  mutate(y = B0 + b0 + x * (B1 + b1) + E)\n\ndata <- expand.grid(group = as.factor(seq(1:4)), \n                    obs = as.factor(seq(1:100)))\ndata.1 <- expand.grid(group = as.factor(5),\n          obs = as.factor(seq(1:30)))\n\ndata <- bind_rows(data, data.1) %>% \n  left_join(rand_eff,\n            by = \"group\") %>%\n  mutate(x = runif(n = nrow(.), 0, 10),\n         B0 = 20,\n         B1 = 2,\n         E = rnorm(n = nrow(.), 0, 10)) %>%\n  mutate(y = B0 + b0 + x * (B1 + b1) + E)\ndata %>% \n  select(x, y, group, obs) %>% \n  head()"},{"path":"foundations-of-mixed-modelling.html","id":"all-in-one-model","chapter":"1 Foundations of Mixed Modelling","heading":"1.3.1 All in one model","text":"begin highlighting importance considering data structure hierarchy building linear models. illustrate , delve example showcases consequences ignoring underlying data structure. might naively construct single linear model ignores group-level variation treats observations independent. oversimplified approach fails account fact observations within groups similar due shared characteristics.\\[Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i\\]can see basic linear model produced statistically significant regression analysis (t998 = 11.24, p <0.001) \\(R^2\\) 0.11. medium effect positive relationship changes x y (Estimate = 2.765, S.E. = 0.25).can see clearly produce simple plot x y:\nFigure 1.1: Simple scatter plot x y\nuse function geom_smooth() scatter plot, plot also includes fitted regression line obtained using \"lm\" method. allows us examine overall trend potential linear association variables.\nFigure 1.2: Scatter plot displaying relationship independent variable dependent variable. points represent observed data, fitted regression line represents linear relationship variables. plot helps visualize trend potential association variables.\ncheck_model() function performance package (Lüdecke et al. (2023)) used evaluate performance diagnostic measures statistical model. provides comprehensive assessment model's fit, assumptions, predictive capabilities. calling function, can obtain summary various evaluation metrics diagnostic plots specified model.enables identify potential issues, violations assumptions, influential data points, lack fit, can affect interpretation reliability model's resultsLooking fit model tempted conclude accurate robust model.However, data hierarchically structured, individuals nested within groups, typically correlation similarity among observations within group. accounting clustering effect, estimates derived single model can biased inefficient. assumption independence among observations violated, leading incorrect standard errors inflated significance levels.figure can see difference median range x values within groups:\nFigure 1.3: Linear model conducted data\nfigure, colour tag data points group, can useful determining mixed model appropriate.:colour-coding data points based grouping variable, plot allows visually assess within-group -group variability. noticeable differences data patterns dispersion among groups, suggests data may hierarchical structure, observations within group similar observations groups.plots, confirms observations within ranges aren’t independent. can’t ignore : ’re starting see, lead completely erroneous conclusion.","code":"\nbasic_model <- lm(y ~ x, data = data)\nsummary(basic_model)## \n## Call:\n## lm(formula = y ~ x, data = data)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -37.23 -12.11  -2.36  11.00  44.53 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  21.0546     1.6490  12.768   <2e-16 ***\n## x             2.5782     0.2854   9.034   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 16.96 on 428 degrees of freedom\n## Multiple R-squared:  0.1602, Adjusted R-squared:  0.1582 \n## F-statistic: 81.62 on 1 and 428 DF,  p-value: < 2.2e-16\nplot(data$x, data$y)\nggplot(data, aes(x = x, \n                 y = y)) +\n  geom_point() +\n  labs(x = \"Independent Variable\", \n       y = \"Dependent Variable\")+\n  geom_smooth(method = \"lm\")\nperformance::check_model(basic_model)\nggplot(data, aes(x = group, \n                 y = y)) +\n  geom_boxplot() +\n  labs(x = \"Groups\", \n       y = \"Dependent Variable\")\n# Color tagged by group\nplot_group <- ggplot(data, aes(x = x, \n                               y = y, \n                               color = group,\n                               group = group)) +\n  geom_point(alpha = 0.6) +\n  labs(title = \"Data Coloured by Group\", \n       x = \"Independent Variable\", \n       y = \"Dependent Variable\")+\n  theme(legend.position=\"none\")\n\nplot_group"},{"path":"foundations-of-mixed-modelling.html","id":"multiple-analyses-approach","chapter":"1 Foundations of Mixed Modelling","heading":"1.3.2 Multiple analyses approach","text":"Running separate linear models per group, also known stratified analysis, can feasible approach certain situations. However, several drawbacks includingIncreased complexityIncreased complexityInability draw direct conclusions overall variabilityInability draw direct conclusions overall variabilityReduced statistical powerReduced statistical powerInflated Type 1 error riskInflated Type 1 error riskInconsistent estimatesInconsistent estimatesLimited ability handle unbalanced/missing dataLimited ability handle unbalanced/missing data\nFigure 1.4: Scatter plot showing relationship independent variable (x) dependent variable (y) colored group. subplot represents different group. line represents group-level linear regression smoothing.\ncode , dataset data first grouped variable 'group' using group_by function, data within group nested using nest function. results new dataset nested_data group's data stored nested tibble.Next, linear regression model (lm) fit nested data group using map function. broom::tidy function applied model using map extract model summary statistics, coefficients, p-values, standard errors. resulting models stored models object.bind_rows function used combine model results single data frame called combined_models. data frame filtered include rows predictor 'x' using filter function, resulting filtered_models data frame.add column group index, rowid_to_column function applied filtered_models data frame, creating group_indexed_models data frame additional column named 'group'.Finally, p-values group_indexed_models data frame modified using custom function report_p","code":"\n# Plotting the relationship between x and y with group-level smoothing\nggplot(data, aes(x = x, y = y, color = group, group = group)) +\n  geom_point(alpha = 0.6) +  # Scatter plot of x and y with transparency\n  labs(title = \"Data Colored by Group\", x = \"Independent Variable\", y = \"Dependent Variable\") +\n  theme(legend.position = \"none\") +\n  geom_smooth(method = \"lm\") +  # Group-level linear regression smoothing\n  facet_wrap(~group)  # Faceting the plot by group\n# Creating nested data by grouping the data by 'group'\nnested_data <- data %>%\n  group_by(group) %>%\n  nest()\n\n# Fitting linear regression models to each nested data group\nmodels <- map(nested_data$data, ~ lm(y ~ x, data = .)) %>% \n          map(broom::tidy)\n\n# Combining the model results into a single data frame\ncombined_models <- bind_rows(models)\n\n# Filtering the rows to include only the 'x' predictor\nfiltered_models <- combined_models %>%\n                   filter(term == \"x\")\n\n# Adding a column for the group index using rowid_to_column function\ngroup_indexed_models <- filtered_models %>%\n                        rowid_to_column(\"group\")\n\n# Modifying the p-values using a custom function report_p\nfinal_models <- group_indexed_models %>%\n                mutate(p.value = report_p(p.value))\n\nfinal_models\n report_p <- function(p, digits = 3) {\n     reported <- if_else(p < 0.001,\n             \"p < 0.001\",\n             paste(\"p=\", round(p, digits)))\n     \n     return(reported)\n }"},{"path":"foundations-of-mixed-modelling.html","id":"complex-model","chapter":"1 Foundations of Mixed Modelling","heading":"1.3.3 Complex model","text":"Using group level term interaction x fixed effect means explicitly including interaction term x group predictor model equation. approach assumes relationship x outcome variable differs across groups differences constant fixed. implies group unique intercept (baseline level) slope (effect size) relationship x outcome variable. treating group level term fixed effect, model estimates specific parameter values group.explicitly interested outcomes differences individual group (wish account ) - may best option can lead overfitting uses lot degrees freedom - impacting estimates widening confidence intervals. running multiple models , limited ability make inferences outside observed groups, handle missing data unbalanced designs well.\\[Y_i = \\beta_0 + \\beta_1X_i + \\beta_2.group_i+\\beta_3(X_i.group_i)+\\epsilon_i\\]","code":"\nadditive_model <- lm(y ~ x*group, data = data)\n\nsummary(additive_model)## \n## Call:\n## lm(formula = y ~ x * group, data = data)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -24.8614  -6.2579   0.2044   6.9342  28.5474 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   6.8125     1.8881   3.608 0.000346 ***\n## x             3.0644     0.3379   9.070  < 2e-16 ***\n## group2        6.4526     2.7289   2.365 0.018505 *  \n## group3       44.8356     2.8539  15.710  < 2e-16 ***\n## group4       15.8607     2.7184   5.835 1.08e-08 ***\n## group5       22.9090     4.0772   5.619 3.51e-08 ***\n## x:group2     -0.5481     0.4875  -1.124 0.261560    \n## x:group3     -1.6739     0.4781  -3.501 0.000513 ***\n## x:group4     -1.3787     0.4830  -2.855 0.004522 ** \n## x:group5     -3.1400     0.7479  -4.198 3.28e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 9.801 on 420 degrees of freedom\n## Multiple R-squared:  0.7246, Adjusted R-squared:  0.7187 \n## F-statistic: 122.8 on 9 and 420 DF,  p-value: < 2.2e-16"},{"path":"foundations-of-mixed-modelling.html","id":"our-first-mixed-model","chapter":"1 Foundations of Mixed Modelling","heading":"1.4 Our first mixed model","text":"mixed model good choice : allow us use data (higher sample size) account correlations data coming groups. also estimate fewer parameters avoid problems multiple comparisons encounter using separate regressions.can now join random effect \\(U_j\\) full dataset define y values \\[Y_{ij} = β_0 + β_1*X_{ij} + U_j + ε_{ij}\\].response variable, attempting explain part variation test score fitting independent variable fixed effect. response variable residual variation (.e. unexplained variation) associated group. using random effects, modeling unexplained variation variance.now want know association y ~ x exists controlling variation group.","code":""},{"path":"foundations-of-mixed-modelling.html","id":"running-mixed-effects-models-with-lmertest","chapter":"1 Foundations of Mixed Modelling","heading":"1.4.1 Running mixed effects models with lmerTest","text":"section detail run mixed models lmer function R package lmerTest (Kuznetsova et al. (2020)). builds older lme4 (Bates et al. (2023)) package, particular add p-values previously included. R packages can used run mixed-effects models including nlme package (Pinheiro et al. (2023)) glmmTMB package (Brooks et al. (2023)). Outside R also packages software capable running mixed-effects models, though arguably none better supported R software.groups clearly explain lot varianceSo differences groups explain ~67% variance ’s “left ” variance explained fixed effects.","code":"\nplot_function2 <- function(model, title = \"Data Coloured by Group\"){\n  \ndata <- data %>% \n  mutate(fit.m = predict(model, re.form = NA),\n         fit.c = predict(model, re.form = NULL))\n\ndata %>%\n  ggplot(aes(x = x, y = y, col = group)) +\n  geom_point(pch = 16, alpha = 0.6) +\n  geom_line(aes(y = fit.c, col = group), linewidth = 2)  +\n  coord_cartesian(ylim = c(-40, 100))+\n  labs(title = title, \n       x = \"Independent Variable\", \n       y = \"Dependent Variable\") \n}\n\nmixed_model <- lmer(y ~ x + (1|group), data = data)\n\nplot_function2(mixed_model, \"Random intercept\")\n# random intercept model\nmixed_model <- lmer(y ~ x + (1|group), data = data)\n\nsummary(mixed_model)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: y ~ x + (1 | group)\n##    Data: data\n## \n## REML criterion at convergence: 3224.4\n## \n## Scaled residuals: \n##      Min       1Q   Median       3Q      Max \n## -2.61968 -0.63654 -0.03584  0.66113  3.13597 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev.\n##  group    (Intercept) 205      14.32   \n##  Residual             101      10.05   \n## Number of obs: 430, groups:  group, 5\n## \n## Fixed effects:\n##             Estimate Std. Error       df t value Pr(>|t|)    \n## (Intercept)  23.2692     6.4818   4.1570    3.59   0.0215 *  \n## x             2.0271     0.1703 424.0815   11.90   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##   (Intr)\n## x -0.131\n205/(205 + 101) = 0.669 / 66.9%\n"},{"path":"foundations-of-mixed-modelling.html","id":"partial-pooling","chapter":"1 Foundations of Mixed Modelling","heading":"1.4.2 Partial pooling","text":"worth noting random effect estimates function group-level information overall (grand) mean random effect. Group levels low sample size poor information (.e., strong relationship) strongly influenced grand mean, adds information otherwise poorly-estimated group. However, group large sample size strong information (.e., strong relationship) little influence grand mean largely reflect information contained entirely within group. process called partial pooling (opposed pooling, effect considered, total pooling, separate models run different groups). Partial pooling results phenomenon known shrinkage, refers group-level estimates shrunk toward mean. mean? use random effect, prepared factor levels influence overall mean levels. good, clear signal group, won’t see much impact overall mean, small groups without much signal.can take look estimates standard errors three previously constructed models:Pooling helps improve precision estimates borrowing strength entire dataset. However, can also lead differences estimates standard errors compared models without pooling.Pooled: pooled model averaged estimates may accurately reflect true values within group. result, estimates pooled models can biased towards average behavior across groups. can see small standard error intercept, underestimating variance dataset. time substantial variability relationships groups, pooled estimates can less precise. increased variability across groups can contribute larger standard errors difference (SED) fixed effects pooled models.Pooled: pooled model averaged estimates may accurately reflect true values within group. result, estimates pooled models can biased towards average behavior across groups. can see small standard error intercept, underestimating variance dataset. time substantial variability relationships groups, pooled estimates can less precise. increased variability across groups can contribute larger standard errors difference (SED) fixed effects pooled models.pooling: model extremely precise smallest errors, however estimates reflect conditions first group modelNo pooling: model extremely precise smallest errors, however estimates reflect conditions first group modelPartial pooling/Mixed models: model reflects greater uncertainty Mean SE intercept. However, SED partial pooling model accounts variability within groups uncertainty groups. Compared pooling approach, SED partial pooling model tends smaller incorporates pooled information, reduces overall uncertainty. adjusted SED provides accurate measure uncertainty associated estimated differences groups fixed effects.Partial pooling/Mixed models: model reflects greater uncertainty Mean SE intercept. However, SED partial pooling model accounts variability within groups uncertainty groups. Compared pooling approach, SED partial pooling model tends smaller incorporates pooled information, reduces overall uncertainty. adjusted SED provides accurate measure uncertainty associated estimated differences groups fixed effects.","code":"\npooled <- basic_model %>% \n  broom::tidy() %>% \n  mutate(Approach = \"Pooled\", .before = 1) %>% \n  select(term, estimate, std.error, Approach)\n\nno_pool <- additive_model %>% \n  broom::tidy() %>% \n  mutate(Approach = \"No Pooling\", .before = 1) %>% \n  select(term, estimate, std.error, Approach)\n\npartial_pool <- mixed_model %>% \n  broom.mixed::tidy() %>% \n  mutate(Approach = \"Mixed Model/Partial Pool\", .before = 1) %>% \n  select(Approach, term, estimate, std.error)\n\nbind_rows(pooled, no_pool, partial_pool) %>% \n  filter(term %in% c(\"x\" , \"(Intercept)\") )"},{"path":"foundations-of-mixed-modelling.html","id":"predictions","chapter":"1 Foundations of Mixed Modelling","heading":"1.5 Predictions","text":"One misconception mixed-effects models produce estimates relationships group.?can use coef() function extract estimates (strictly predictions) random effects. output several components.function produces 'best linear unbiased predictions' (BLUPs) intercept slope regression site. predictions given different get ran individual models site, BLUPs product compromise complete-pooling -pooling models. Now predicted intercept influenced sites leading process called 'shrinkage'.called predictions estimates? estimated variance site essentially borrowed information across sites improve accuracy, combine fixed effects. strictest sense predicting relationships rather direct observation.generous ability make predictions one main advantages mixed-model.summary() function already provided estimates fixed effects, can also extracted fixef() function.can also apply anova() single model get F-test fixed effect","code":"\ncoef(mixed_model)## $group\n##   (Intercept)        x\n## 1    11.82356 2.027066\n## 2    15.68146 2.027066\n## 3    47.94678 2.027066\n## 4    21.01028 2.027066\n## 5    19.88385 2.027066\n## \n## attr(,\"class\")\n## [1] \"coef.mer\"\nfixef(mixed_model)## (Intercept)           x \n##   23.269187    2.027066\nanova(mixed_model)"},{"path":"foundations-of-mixed-modelling.html","id":"shrinkage-in-mixed-models","chapter":"1 Foundations of Mixed Modelling","heading":"1.5.1 Shrinkage in mixed models","text":"graph demonstrates compromise complete pooling pooling. plots overall regression line/mean (fixed effects lmer model), predicted slopes site mixed-effects model, compares estimates site (nested lm).can see groups show shrinkage, deviate less overall mean, obviously group 5, sample size deliberately reduced. can see predicted line much closer overall regression line, reflecting greater uncertainty. slope drawn towards overall mean shrinkage.\nFigure 1.5: Regression relationships fixed-effects mixed effects models, note shrinkage group 5\nre.form = NA: re.form set NA, indicates random effects ignored prediction. means prediction based solely fixed effects model, ignoring variation introduced random effects. useful interested estimating overall trend relationship described fixed effects, without considering specific random effects individual groups levels.re.form = NULL: Conversely, re.form set NULL, indicates random effects included prediction. means prediction take account fixed effects random effects associated levels random effect variable. model use estimated random effects generate predictions account variation introduced random effects. useful want visualize analyze variation response variable explained different levels random effect.always easy/straightforward make prediciton confidence intervals complex general generalized linear mixed models, luckily excellent R packages us.","code":"\n# Nesting the data by group\nnested_data <- data %>% \n    group_by(group) %>% \n    nest()\n\n# Fitting linear regression models and obtaining predictions for each group\nnested_models <- map(nested_data$data, ~ lm(y ~ x, data = .)) %>% \n    map(predict)\n# Creating a new dataframe and adding predictions from different models\ndata1 <- data %>% \n  mutate(fit.m = predict(mixed_model, re.form = NA),\n         fit.c = predict(mixed_model, re.form = NULL)) %>% \n  arrange(group,obs) %>% \n  mutate(fit.l = unlist(nested_models)) \n\n# Creating a plot to visualize the predictions\ndata1 %>% \n  ggplot(aes(x = x, y = y, colour = group)) +\n    geom_point(pch = 16) + \n  geom_line(aes(y = fit.l, linetype = \"lm\"), colour = \"black\")+\n  geom_line(aes(y = fit.c, linetype = \"lmer\"))+ \n  geom_line(aes(y = fit.m, linetype = \"Mean\"), colour = \"grey\")+\n   scale_linetype_manual(name = \"Model Type\", \n                        labels = c(\"Mean\", \"lmer\", \"lm\"),\n                        values = c(\"dotdash\", \"solid\", \"dashed\"))+\n  facet_wrap( ~ group)+\n  guides(colour = \"none\")"},{"path":"foundations-of-mixed-modelling.html","id":"ggeffects","chapter":"1 Foundations of Mixed Modelling","heading":"1.5.2 ggeffects","text":"ggeffects (Lüdecke (2023a)) light-weight package aims easily calculating marginal effects adjusted predictions","code":""},{"path":"foundations-of-mixed-modelling.html","id":"ggpredict","chapter":"1 Foundations of Mixed Modelling","heading":"1.5.2.1 ggpredict","text":"argument type = random ggpredict function (ggeffects package Lüdecke (2023a)) used specify type predictions generated context mixed effects models. main difference using ggpredict without type = random lies type predictions produced:Without type = random: ggpredict generate fixed-effects predictions. estimates based solely fixed effects model, ignoring variability associated random effects. resulting estimate represent average expected values response variable specific combinations predictor values, considering fixed components model.Estimated mean fixed effects provide comprehensive view average effect dependent variables response variable. plotting estimated mean fixed effects using ggpredict, can visualize response variable changes across different levels values predictors considering effects variables model.type = random: ggpredict generate predictions incorporate fixed random effects. predictions take account variability introduced random effects model. resulting predictions reflect average trend captured fixed effects also additional variability associated random effects different levels grouping factor(s).default figure now produces prediciton intervals\nConfidence Intervals: confidence interval used estimate \nrange plausible values population parameter, mean\nregression coefficient, based sample population.\nprovides range within true population parameter likely\nfall certain level confidence. example, 95%\nconfidence interval implies repeat sampling\nprocess many times, 95% resulting intervals contain \ntrue population parameter.\n\nPrediction Intervals: hand, prediction interval \nused estimate range plausible values individual\nobservation future observation population. takes \naccount uncertainty estimated model parameters \ninherent variability within data. 95% prediction interval provides\nrange within specific observed predicted value likely \nfall certain level confidence. wider prediction\ninterval, greater uncertainty around specific value \npredicted.\nFurthermore, ggpredict() enables explore group-level predictions, provide deeper understanding response variable varies across different levels grouping variable. specifying desired grouping variable ggpredict type = random, can generate plots depict predicted values group separately, allowing comparative analysis group-level effects.","code":"\nlibrary(ggeffects)\n\nggpredict(mixed_model, terms = \"x\") %>% \nplot(., add.data = TRUE)\nggpredict(mixed_model, terms = \"x\", type = \"random\") %>% \nplot(., add.data = TRUE)\nggpredict(mixed_model, terms = c(\"x\", \"group\"), type = \"random\") %>% \nplot(., add.data = TRUE) + \n  facet_wrap(~group)+\n  theme(legend.position = \"none\")"},{"path":"foundations-of-mixed-modelling.html","id":"sjplot","chapter":"1 Foundations of Mixed Modelling","heading":"1.5.3 sjPlot","text":"Another way visualise mixed model results package sjPlot(Lüdecke (2023b)), interested showing variation among levels random effects, can plot departure overall model estimate intercepts - slopes, random slope model:\nvalues see actual values, rather difference\ngeneral intercept slope value found model summary\nestimate specific level random/fixed effect.\nsjPlot also capable producing prediction plots way ggeffects:","code":"\nlibrary(sjPlot)\n\nplot_model(mixed_model, terms = c(\"x\", \"group\"), type = \"re\")/\n  (plot_model(mixed_model, terms = c(\"x\", \"group\"), type = \"est\")+ggtitle(\"Fixed Effects\"))\nplot_model(mixed_model,type=\"pred\",\n           terms=c(\"x\", \"group\"),\n           pred.type=\"re\",\n           show.data = T)+\n  facet_wrap( ~ group)"},{"path":"foundations-of-mixed-modelling.html","id":"checking-model-assumptions","chapter":"1 Foundations of Mixed Modelling","heading":"1.6 Checking model assumptions","text":"need just conscious testing assumptions mixed effects models . assumptions :Within-group errors independent normally distributed mean zero variance \\(\\sigma^2\\)Within-group errors independent normally distributed mean zero variance \\(\\sigma^2\\)Within-group errors independent random effects.Within-group errors independent random effects.Random effects normally distributed mean zero.Random effects normally distributed mean zero.Random effects independent different groups, except specified nesting (later)Random effects independent different groups, except specified nesting (later)Several model check plots help us confirm/deny assumptions, note QQ-plots may relevant model structure. Two commonly-used plots :can often useful check distribution residuals groups (e.g. blocks) check assumptions 1 2. can plotting residuals fitted values, separately level random effect, using coplot() function:sub-figure plot, refers individual group, doesn’t contain much data. can hard judge whether spread residuals around fitted values group observations low.can check assumption 3 histogram (levels , can assured):Overlaying random distribution intercept regression line produces plot like :\nFigure 1.6: Marginal fit, heavy black line random effect model histogram distribution conditional intercepts\n","code":"\nplot(mixed_model) \nqqnorm(resid(mixed_model))\nqqline(resid(mixed_model)) \ncoplot(resid(mixed_model) ~ fitted(mixed_model) | data$group)\nrand_dist <- as.data.frame(ranef(mixed_model)) %>% \n  mutate(group = grp,\n         b0_hat = condval,\n         intercept_cond = b0_hat + summary(mixed_model)$coef[1,1],\n         .keep = \"none\")\n\nhist(rand_dist$b0_hat)\ndata1 %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_point(pch = 16, col = \"grey\") +\n  geom_violinhalf(data = rand_dist, \n                  aes(x = 0, y = intercept_cond), \n                  trim = FALSE, \n                  width = 4, \n                  adjust = 2, \n                  fill = NA)+\n  geom_line(aes(y = fit.m), linewidth = 2)  +\n  coord_cartesian(ylim = c(-40, 100))+\n  labs(x = \"Independent Variable\", \n       y = \"Dependent Variable\")"},{"path":"foundations-of-mixed-modelling.html","id":"performance","chapter":"1 Foundations of Mixed Modelling","heading":"1.6.1 performance","text":"check_model() function performance package R useful tool evaluating performance assumptions statistical model, particularly context mixed models. provides comprehensive set diagnostics visualizations assess model's fit, identify potential issues, verify assumptions underlying model, can difficult complex models","code":"\nlibrary(performance)\ncheck_model(mixed_model)"},{"path":"foundations-of-mixed-modelling.html","id":"dharma","chapter":"1 Foundations of Mixed Modelling","heading":"1.6.2 DHARma","text":"Simulation-based methods, like available DHARMa (Hartig (2022)), often preferred model validation assumption checking offer flexibility rely specific assumptions. Simulation particularly useful evaluating complex models multiple levels variability, non-linearity, complex hierarchical structures. models may adequately evaluated solely examining residuals, simulation provides robust approach assess assumptions performance.Read authors summary \nlot data, even minimal deviations \nexpected distribution become significant (discussed \nhelp/vignette DHARMa package). need assess \ndistribution decide important .\n","code":"\nlibrary(DHARMa)\n\nresid.mm <- simulateResiduals(mixed_model)\n\nplot(resid.mm)"},{"path":"foundations-of-mixed-modelling.html","id":"practice-questions","chapter":"1 Foundations of Mixed Modelling","heading":"1.7 Practice Questions","text":"mixed-effects models, independent variables also called:Random EffectsFixed EffectsMediatorsVarianceA random effect best described ?following advantage mixed-effects models?Mixed-effects models cope well missing data ?","code":""},{"path":"worked-example-1---dolphins.html","id":"worked-example-1---dolphins","chapter":"2 Worked Example 1 - Dolphins","heading":"2 Worked Example 1 - Dolphins","text":"","code":""},{"path":"worked-example-1---dolphins.html","id":"how-do-i-decide-if-it-is-a-fixed-or-random-effect","chapter":"2 Worked Example 1 - Dolphins","heading":"2.1 How do I decide if it is a fixed or random effect?","text":"One common questions mixed-effects modelling decide effect considered fixed random. can quite complicated question, touched upon briefly definition random effect universal. considered process can include hypothesis question asking.1 ) directly interested effect question. answer yes fixed effect.2 ) variable continuous? answer yes fixed effect.3 ) variable less five levels? ther answer yes fixed effect.","code":""},{"path":"worked-example-1---dolphins.html","id":"dolphins","chapter":"2 Worked Example 1 - Dolphins","heading":"2.2 Dolphins","text":"dataset collected measure resting lung function 32 bottlenose dolphins. main dependent variable tidal volume (\\(V_T\\)) measured litres, index lung capacity.interested relationship (\\(V_T\\)) body mass (kg), measurements taken breath breath , dolphin observed one four times.need determine fixed effects, random effects model structure:Body Mass Random EffectFixed EffectBody Mass Random EffectFixed EffectDirection Random EffectFixed EffectDirection Random EffectFixed EffectAnimal 1) Body Mass Random EffectFixed EffectAnimal 1) Body Mass Random EffectFixed EffectWith basic structure y ~ x + z + (1|group) think model ?:basic structure y ~ x + z + (1|group) think model ?:clearly interested effect body mass (\\(V_T\\)) fixed effect.clearly interested effect body mass (\\(V_T\\)) fixed effect.may think relationship (\\(V_T\\)) body mass may different breath. may directly interested , fewer fivel levels fixed effect. (outbreath coded 1, inbreath coded 2).may think relationship (\\(V_T\\)) body mass may different breath. may directly interested , fewer fivel levels fixed effect. (outbreath coded 1, inbreath coded 2).Individual dolphins - averaged across measurements dolphin, measurement precision different animal. include data point, double-counting animals observations independent. account multiple observations treat animal random effect.Individual dolphins - averaged across measurements dolphin, measurement precision different animal. include data point, double-counting animals observations independent. account multiple observations treat animal random effect.basic linear model place - carry model fit checks DHARMa performance::check_model(), assuming good fit can look interpretation:\nFigure 2.1: Scatter plot VT function body mass dolphins. Different directions breath represented different colors. solid lines indicate marginal fitted values model.\nfitted linear mixed model (estimated using REML nloptwrap optimizer) predict (\\(V_T\\)) bodymass(kg) direction (/breath). 95% Confidence Intervals (CIs) p-values computed using Wald t-distribution approximation. included random intercept effect animal account repeated measurements (1 4 observations) across total 32 bottlenosed dolphins.found every 1kg increase bodymass, (\\(V_T\\)) increased 0.02 litres (95% CI [0.01 - 0.02]), \\(t_{107}\\) = 5.15, p < 0.001. inbreath average higher volume outbreath (1.11 litre difference [0.71 - 1.52]; \\(t_{107}\\) = 5.48, p < 0.001).Q. perfect write-, else consider including?","code":"\ndolphins <- read_csv(\"dolphins.csv\") \ndolphmod <- lmer(vt ~ bodymass + direction + (1|animal), data=dolphins)\nsummary(dolphmod)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: vt ~ bodymass + direction + (1 | animal)\n##    Data: dolphins\n## \n## REML criterion at convergence: 387.4\n## \n## Scaled residuals: \n##      Min       1Q   Median       3Q      Max \n## -2.30795 -0.51983  0.04156  0.62404  2.26396 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev.\n##  animal   (Intercept) 1.039    1.019   \n##  Residual             1.158    1.076   \n## Number of obs: 112, groups:  animal, 31\n## \n## Fixed effects:\n##              Estimate Std. Error        df t value Pr(>|t|)    \n## (Intercept)  2.226398   0.627115 28.758081   3.550  0.00135 ** \n## bodymass     0.016782   0.003259 26.720390   5.150  2.1e-05 ***\n## direction2   1.114821   0.203389 77.414421   5.481  5.1e-07 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##            (Intr) bdymss\n## bodymass   -0.927       \n## direction2 -0.162  0.000\ndolphins.1 <- dolphins %>% \n    mutate(fit.m = predict(dolphmod, re.form = NA),\n           fit.c = predict(dolphmod, re.form = NULL))\ndolphins.1 %>%\n  ggplot(aes(x = bodymass, y = vt, group = direction)) +\n  geom_point(pch = 16, aes(colour = direction)) +\n  geom_line(aes(y = fit.m, \n                linetype = direction), \n            linewidth = 1)  +\n  labs(x = \"Body Mass\", \n       y = \"VT\") \nplot_model(dolphmod,type=\"pred\",\n           terms=c(\"bodymass\", \"direction\"),\n           pred.type=\"fe\",\n           show.data = T)"},{"path":"multiple-random-effects.html","id":"multiple-random-effects","chapter":"3 Multiple random effects","heading":"3 Multiple random effects","text":"Previously used (1|group) fit random effect. Whatever right side | operator factor referred “grouping factor” term.","code":""},{"path":"multiple-random-effects.html","id":"crossed-or-nested","chapter":"3 Multiple random effects","heading":"3.0.1 Crossed or Nested","text":"one possible randome effect can crossed nested - depends relationship variables. Let’s look.common issue causes confusion issue specifying random effects either ‘crossed’ ‘nested’. reality, way specify random effects determined experimental sampling design. simple example can illustrate difference.","code":""},{"path":"multiple-random-effects.html","id":"crossed-random-effects","chapter":"3 Multiple random effects","heading":"3.0.1.1 1. Crossed Random Effects:","text":"Crossed random effects occur levels two grouping variables crossed independent . case, grouping variables unrelated, combination levels represented data.\nFigure 3.1: Fully Crossed\nExample 1: consider study examining academic performance students different schools different cities. grouping variables \"School\" \"City\". school can located multiple cities, city can multiple schools. random effects \"School\" \"City\" crossed since levels variables independent .lmer(y ~ x + (1 | School) + (1 | City), data = dataset)Example 2: Imagine long-term study breeding success passerine birds across multiple woodlands, researcher returns every year five years carry measurements. \"Year\" crossed random effect \"Woodland\" Woodland can appear multiple years study.\nImagine researcher interested understanding factors affecting clutch mass passerine bird. study population spread across five separate woodlands, containing 30 nest boxes. Every week breeding measure foraging rate females feeders, measure subsequent clutch mass. females multiple clutches season contribute multiple data points.lmer(y ~ x + (1 | Year) + (1 | Woodland), data = dataset)","code":""},{"path":"multiple-random-effects.html","id":"nested-random-effects","chapter":"3 Multiple random effects","heading":"3.0.1.2 2. Nested Random Effects:","text":"Nested random effects occur levels one grouping variable completely nested within levels another grouping variable. words, levels one variable uniquely exclusively associated specific levels another variable.\nFigure 3.2: Fully Nested\nExample 1. Consider study job performance employees within different departments organization. grouping variables \"Employee\" \"Department\". employee belongs one specific department, employee can part multiple departments. random effects \"Employee\" nested within random effects \"Department\" since employee uniquely associated specific department.lmer(y ~ x + (1 | Department/Employee), data = dataset)Example 2: bird study female ID said nested within woodland : woodland contains multiple females unique woodland (never move among woodlands). nested random effect controls fact () clutches female independent, (ii) females woodland may clutch masses similar one another females woodlandslmer(y ~ x + (1 | Woodland/Female ID), data = dataset)remember year model crossed nested random effectslmer(y ~ x + (1 | Woodland/Female ID) + (1|Year), data = dataset)designing models around crossed nested designs check amazing nature paper Krzywinski et al. (2014)","code":""},{"path":"worked-example-2---nested-design.html","id":"worked-example-2---nested-design","chapter":"4 Worked Example 2 - Nested design","heading":"4 Worked Example 2 - Nested design","text":"experiment involved simple one-way anova 3 treatments given 6 rats. analysis complicated fact three preparations taken liver rat, two readings glycogen content taken preparation. generated 6 pseudoreplicates per rat give total 36 readings .Clearly, mistake analyse data straightforward one-way anova, give us 33 degrees freedom error. fact, since two rats treatment, one degree freedom per treatment, giving total 3 d.f. error.variance likely different level nested analysis :readings differ variation glycogen detection method within liver sample (measurement error);\npieces liver may differ heterogeneity distribution glycogen within liver single rat;\nrats differ one another glycogen levels sex, age, size, genotype, etc.;\nrats allocated different experimental treatments may differ result fixed effects treatment.\nwant test whether experimental treatments affected glycogen levels, interested liver bits within rat’s livers, preparations within liver bits. combine pseudoreplicates together, analyse 6 averages. virtue showing tiny experiment really . latter approach also ignores nested sources uncertainties. Instead use linear mixed model.Q. model wrongIt wrong add two random effect terms, one rat 1 one rat 2. fact 6 rats altogether. way data coded allows kinds mistakes happen. true Liver, coded 1, 2 3. means write thinking including correct random effects Rat Liver. fact, assumes data come crossed design, 2 rats 3 parts liver, Liver = 1 corresponds type measurement rats 1 2 . Sometimes appropriate, !nature way many data sets coded makes kinds mistakes easy make!r unhide()better design one :can see effects figures :","code":"\nrats <- readRDS(\"rats.rds\")\nrats %>% \n  aggregate(Glycogen ~ Rat + Treatment + Liver, data = ., mean)   Glycogen Rat Treatment Liver\n1       131   1         1     1\n2       130   1         1     1\n3       131   1         1     2\n4       125   1         1     2\n5       136   1         1     3\n6       142   1         1     3\n7       150   2         1     1\n8       148   2         1     1\n9       140   2         1     2\n10      143   2         1     2\n11      160   2         1     3\n12      150   2         1     3\n13      157   3         2     1\n14      145   3         2     1\n15      154   3         2     2\n16      142   3         2     2\n17      147   3         2     3\n18      153   3         2     3\n19      151   4         2     1\n20      155   4         2     1\n21      147   4         2     2\n22      147   4         2     2\n23      162   4         2     3\n24      152   4         2     3\n25      134   5         3     1\n26      125   5         3     1\n27      138   5         3     2\n28      138   5         3     2\n29      135   5         3     3\n30      136   5         3     3\n31      138   6         3     1\n32      140   6         3     1\n33      139   6         3     2\n34      138   6         3     2\n35      134   6         3     3\n36      127   6         3     3\n\nrats_lmer.1 <- lmer(Glycogen ~ Treatment + (1 | Rat) + (1 | Liver), data = rats)\nsummary(rats_lmer.1)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: Glycogen ~ Treatment + (1 | Rat) + (1 | Liver)\n##    Data: rats\n## \n## REML criterion at convergence: 221.9\n## \n## Scaled residuals: \n##      Min       1Q   Median       3Q      Max \n## -1.79334 -0.66536  0.01792  0.59281  2.05206 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev.\n##  Rat      (Intercept) 39.187   6.260   \n##  Liver    (Intercept)  2.168   1.472   \n##  Residual             30.766   5.547   \n## Number of obs: 36, groups:  Rat, 6; Liver, 3\n## \n## Fixed effects:\n##             Estimate Std. Error      df t value Pr(>|t|)    \n## (Intercept)  140.500      4.783   3.174  29.373 5.65e-05 ***\n## Treatment2    10.500      6.657   3.000   1.577    0.213    \n## Treatment3    -5.333      6.657   3.000  -0.801    0.482    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##            (Intr) Trtmn2\n## Treatment2 -0.696       \n## Treatment3 -0.696  0.500\nrats_lmer.2 <- lmer(Glycogen ~ Treatment + (1 | Rat / Liver), data = rats)\nsummary(rats_lmer.2)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: Glycogen ~ Treatment + (1 | Rat/Liver)\n##    Data: rats\n## \n## REML criterion at convergence: 219.6\n## \n## Scaled residuals: \n##      Min       1Q   Median       3Q      Max \n## -1.48212 -0.47263  0.03062  0.42934  1.82935 \n## \n## Random effects:\n##  Groups    Name        Variance Std.Dev.\n##  Liver:Rat (Intercept) 14.17    3.764   \n##  Rat       (Intercept) 36.06    6.005   \n##  Residual              21.17    4.601   \n## Number of obs: 36, groups:  Liver:Rat, 18; Rat, 6\n## \n## Fixed effects:\n##             Estimate Std. Error      df t value Pr(>|t|)    \n## (Intercept)  140.500      4.707   3.000  29.848 8.26e-05 ***\n## Treatment2    10.500      6.657   3.000   1.577    0.213    \n## Treatment3    -5.333      6.657   3.000  -0.801    0.482    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##            (Intr) Trtmn2\n## Treatment2 -0.707       \n## Treatment3 -0.707  0.500\nplot(ggpredict(rats_lmer.2, terms = c(\"Treatment\")))\nplot(ggpredict(rats_lmer.2, \n               terms = c(\"Treatment\", \"Rat\"), \n               type = \"random\"), \n     add.data = TRUE)"},{"path":"types-of-random-effects.html","id":"types-of-random-effects","chapter":"5 Types of Random Effects","heading":"5 Types of Random Effects","text":"","code":""},{"path":"types-of-random-effects.html","id":"random-slopes","chapter":"5 Types of Random Effects","heading":"5.1 Random slopes","text":"far looked random effects group intercept. means fit regression line across five groups, constant slope allowed shift group. represented panel B.alternative random intercepts model random slopes model, shown panel C. model slopes permitted vary, intercept fixed across groups. current data random slopes model fair job well.Finally can allow intercepts slope vary groups, shown panel D. captures shallower slope groups vertical offsets present. inspect original data set generated, can see random effect group calculated product random distribution intercept slope, surprising model fits data best.model use degrees freedom two, must used calculate variance intercept slope.Mixed-effects models enormously flexible. decision whether include random intercepts, random slopes, depend heavily hypotheses. generally quite rare see random slopes models , commonly question whether random intercepts random intercepts random slopes necessary.combine random slopes intercept model requries degrees freedom, may case using likelihood ratio tests (LRT) advisable decide model describes data best (later).random intercepts models require fewer degrees freedome, may easier fit data sets fewer observations.\nrandom effects model, random effects assumed \nrandom sample population possible random effects. random\neffects capture variation different groups clusters \ndata. number random effects typically smaller \ntotal number observations, random effects represent \ndistinct groups clusters dataset.\n\ndegrees freedom associated random effects linear\nmixed model reflect number independent groups clusters \ndata, rather number individual observations. example, \ndata 100 individuals, belong 10 distinct\ngroups, random effects 10 degrees freedom, \n100.\n\nusing fewer degrees freedom random effects, model\naccounts fact group-level variation estimated based\nsmaller number parameters. approach helps prevent\noverfitting provides appropriate estimation variance\ncomponents associated random effects.\n","code":"\n# random intercept model\nlmer1 <- lmer(y ~ x + (1|group), data = data)\n\nplot_function(lmer1, \"Random intercept\")\n\n# Random slope model\n\nlmer2 <- lmer(y ~ x + (0 + x | group), data = data)\n\nplot_function(lmer2, \"Random slope\")\n\n# Random slope and intercept model\n\nlmer3 <- lmer(y ~ x + (x | group), data = data)"},{"path":"types-of-random-effects.html","id":"model-refining-likelihood-ratio-tests","chapter":"5 Types of Random Effects","heading":"5.2 Model refining / Likelihood Ratio Tests","text":"produce initial model random effects structure, may wish perform model selection comparing different nested models varying random effects structures. allows us assess whether inclusion additional random effects changes random effects structure significantly improve model fit. comparing likelihood values different nested models, can determine model provides better fit data.Previously looked random intercepts vs. random intercepts slopes model concluded latter looked like fit data best.can use likelihood ratio test anova() function want determine fit significantly different simpler randome intercepts model.\nliterature idea model selection, , \nautomated (sometimes manual) way testing many versions model\ndifferent subset predictors attempt find \nmodel fits best. sometimes called “stepwise”\nprocedures.\n\nOthers argue method number flaws, including:\n\n\nbasically “p-value mining”, , running lot\ntests till find p-value like.\n\n\nbasically “p-value mining”, , running lot\ntests till find p-value like.\n\n\nlikelihood making false positive high.\n\n\nlikelihood making false positive high.\n\n\nAdding/removing new variable can effect \npredictors.\n\n\nAdding/removing new variable can effect \npredictors.\n\nInstead model selection, use knowledge \ndata select subset variables either ) \nimportance , b) theoretically influential outcome. \ncan fit single model including .\n\nHowever, argue inclusion random effects \nstructure clear rationale implementation,\nadjustments better understand best type random effects\nstructure perfectly reasonable.\nFrequentist fit used LMM lme4 / lmer based Maximum Likelihood principle, maximize likelihood \\(L(y)\\) observing data \\(y\\), equivalent minimizing residuals model, Ordinary Least Squares (OLS) approach. measures probability observing data given specific set parameter values.attempting optimise model can use likelihood ratio test (LRT). Given two nested models, denoted Model 1 Model 2, LRT compares likelihood values models assess whether complex Model 2 provides significantly better fit data compared simpler Model 1. LRT statistic, denoted \\(D\\), calculated difference log-likelihood values Model 1 Model 2, multiplied 2:\\[D = -2~*~(ln(L_1)-ln(L_2))\\]\\(L_1\\) represents likelihood value Model 1, \\(L_2\\) represents likelihood value Model 2. LRT statistic follows chi-square (\\(\\chi^2\\)) distribution degrees freedom equal difference number parameters two models.determine statistical significance LRT statistic, one can compare critical value chi-square distribution appropriate degrees freedom. LRT statistic exceeds critical value, indicates complex Model 2 provides significantly better fit data compared simpler Model 1.ML estimation often used perform hypothesis tests, including chi-square test. chi-square test compares observed data expected data predicted statistical model. assesses goodness--fit observed data model's predictions.REML (Restricted Maximum Likelihood) estimation variant ML estimation addresses issue bias estimation random effects mixed effects models. mixed effects models, random effects account variation group individual level explained fixed effects. However, inclusion random effects introduces bias ML estimates, influenced variability random effects.REML estimation addresses bias optimizing likelihood function conditional fixed effects , effectively removing influence random effects estimation. approach provides unbiased estimates fixed effects especially useful primary interest lies fixed effects rather random effects.Maximum Likelihood (ML) estimation preferable comparing nested models allows direct comparison likelihood values different models. ML estimation provides quantitative measure well given model fits observed data, based likelihood function.context, ML estimation preferable allows formal statistical comparison nested models. provides rigorous objective way assess whether inclusion additional parameters complex model leads significantly better fit data compared simpler model. approach ensures model comparisons based sound statistical principles helps determining appropriate model given data.REML can preferable producing unbiased estimates fixed effects. Older versions model fitting packages like lmer used require manual switch REML ML fitting models order switch objectives assessing goodness--fit interpreting estimates. notice perform LRT anova() function informs switch made automatically.","code":"\nanova(lmer1, lmer3)"},{"path":"types-of-random-effects.html","id":"maximum-likelihood","chapter":"5 Types of Random Effects","heading":"5.2.1 Maximum Likelihood","text":"Frequentist fit used LMM lme4 / lmer based Maximum Likelihood principle, maximize likelihood \\(L(y)\\) observing data \\(y\\), equivalent minimizing residuals model, Ordinary Least Squares (OLS) approach. measures probability observing data given specific set parameter values.attempting optimise model can use likelihood ratio test (LRT). Given two nested models, denoted Model 1 Model 2, LRT compares likelihood values models assess whether complex Model 2 provides significantly better fit data compared simpler Model 1. LRT statistic, denoted \\(D\\), calculated difference log-likelihood values Model 1 Model 2, multiplied 2:\\[D = -2~*~(ln(L_1)-ln(L_2))\\]\\(L_1\\) represents likelihood value Model 1, \\(L_2\\) represents likelihood value Model 2. LRT statistic follows chi-square (\\(\\chi^2\\)) distribution degrees freedom equal difference number parameters two models.determine statistical significance LRT statistic, one can compare critical value chi-square distribution appropriate degrees freedom. LRT statistic exceeds critical value, indicates complex Model 2 provides significantly better fit data compared simpler Model 1.ML estimation often used perform hypothesis tests, including chi-square test. chi-square test compares observed data expected data predicted statistical model. assesses goodness--fit observed data model's predictions.","code":""},{"path":"types-of-random-effects.html","id":"reml","chapter":"5 Types of Random Effects","heading":"5.2.2 REML","text":"REML (Restricted Maximum Likelihood) estimation variant ML estimation addresses issue bias estimation random effects mixed effects models. mixed effects models, random effects account variation group individual level explained fixed effects. However, inclusion random effects introduces bias ML estimates, influenced variability random effects.REML estimation addresses bias optimizing likelihood function conditional fixed effects , effectively removing influence random effects estimation. approach provides unbiased estimates fixed effects especially useful primary interest lies fixed effects rather random effects.","code":""},{"path":"types-of-random-effects.html","id":"ml-vs.-reml-fitting","chapter":"5 Types of Random Effects","heading":"5.2.3 ML vs. REML fitting","text":"Maximum Likelihood (ML) estimation preferable comparing nested models allows direct comparison likelihood values different models. ML estimation provides quantitative measure well given model fits observed data, based likelihood function.context, ML estimation preferable allows formal statistical comparison nested models. provides rigorous objective way assess whether inclusion additional parameters complex model leads significantly better fit data compared simpler model. approach ensures model comparisons based sound statistical principles helps determining appropriate model given data.REML can preferable producing unbiased estimates fixed effects. Older versions model fitting packages like lmer used require manual switch REML ML fitting models order switch objectives assessing goodness--fit interpreting estimates. notice perform LRT anova() function informs switch made automatically.","code":""},{"path":"types-of-random-effects.html","id":"practice-questions-1","chapter":"5 Types of Random Effects","heading":"5.3 Practice Questions","text":"formula y ~ x + (x|group) fit model \n\nRandom SlopesRandom InterceptsRandom Slopes InterceptsAn intercept fixed 0\nformula fit random intercepts model?\n\ny ~ x + (x|group)y ~ x + (1|group)y ~ x + (y | group)\n","code":""},{"path":"worked-example-3---complex-designs.html","id":"worked-example-3---complex-designs","chapter":"6 Worked Example 3 - Complex Designs","heading":"6 Worked Example 3 - Complex Designs","text":"definitely complicated experiment analyse workbook, result complex data hierarchy.","code":""},{"path":"worked-example-3---complex-designs.html","id":"the-data","chapter":"6 Worked Example 3 - Complex Designs","heading":"6.1 The data","text":"BIODEPTH (Biodiversity Ecosystem Process Terrestrial Herbaceous Ecosystems) project manipulated grassland plant diversity field plots simulate impact loss plant species ecosystem processes ground yield.gradient managed species diversity five levels ranging monoculture attempted maximum site. repeated eight different grassland sites across seven countries.level diversity repeated different mixtures plant species chosen random, designed separate features diversity species composition.Experiments repeated two blocks per site.Important variables :Shoot2 one variables representing yield, response dependent variable.Shoot2 one variables representing yield, response dependent variable.Diversity2 Species richness indicator (log base 2 scale)Diversity2 Species richness indicator (log base 2 scale)Block, Site, Mix random effectsBlock, Site, Mix random effectsWhat follows complex design, hopefully outline careful thought must go designing mixed-modelsQ. Discussion - wrong design?Overall, model assumes response variable \"Shoot2\" influenced fixed effect \"Diversity2\" accounting random effects due varying levels \"Site,\" \"Block,\" \"Mix\" within data.also suffers fact design may nested crossed, explicit. Basically know block exists within site, nested. block unique code ok, example coded Germany: /B, Switzerland /B etc... need make design explicity e.g. Site/Block.model also allow random slopes, may wish consider.Q. Discuss two designsIn designs produced random slope intercept effect Site. makes sense think way diversity affects yield may vary random site-specific manner.nesting interaction Site Mix?1 | Site/Mix specification represents nested random effect structure. suggests random effect Mix nested within random effect Site. specification assumes levels Mix nested within level Site, meaning level Site set random effects levels Mix. / operator denotes nesting relationship.hand 1 | Site:Mix specification, random effect specified two-way crossed random effect. means random effect varies independently combination levels Site Mix factors. : operator represents interaction crossed effect two factors. specification allows correlations random effects within combination Site Mix.summarize:1 | Site:Mix: Two-way crossed random effect, allowing independent variation random effects combination levels Site Mix.1 | Site/Mix: Nested random effect, random effect Mix nested within random effect Site, assuming levels Mix completely nested within level Site.Q. LRT indicate effect block model?remove model? YesNoThe LRT indicates removing block design model produce simpler model explains significantly less variance. effect remove . However, argue also harm model part explicit design, left .","code":"\nbiodepth <- read_csv(\"files/Biodepth.csv\")\nhead(biodepth)\nbio.lmer1 <- lmer(Shoot2 ~ Diversity2 + (1|Site) + (1|Block) + (1|Mix), data = biodepth)\n\nsummary(bio.lmer1)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: Shoot2 ~ Diversity2 + (1 | Site) + (1 | Block) + (1 | Mix)\n##    Data: biodepth\n## \n## REML criterion at convergence: 6082.6\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -2.2187 -0.5179 -0.1031  0.3941  3.1735 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev.\n##  Mix      (Intercept) 33665.3  183.48  \n##  Block    (Intercept)   383.2   19.57  \n##  Site     (Intercept) 30163.9  173.68  \n##  Residual             22039.8  148.46  \n## Number of obs: 451, groups:  Mix, 192; Block, 15; Site, 8\n## \n## Fixed effects:\n##             Estimate Std. Error      df t value Pr(>|t|)    \n## (Intercept)  349.488     66.244   8.576   5.276 0.000598 ***\n## Diversity2    78.901     12.059 175.159   6.543 6.42e-10 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##            (Intr)\n## Diversity2 -0.286\nbio.lmer1a <- lmer(Shoot2 ~ Diversity2 + (Diversity2 | Site) + (1 | Site/Mix) + (1 | Block), data = biodepth)\n\n#Site/Mix denotes that Mix is nested fully within Site\nbio.lmer2 <- lmer(Shoot2 ~ Diversity2 + (Diversity2|Site) + (1 | Site:Mix) + (1|Mix) + (1 | Block), data = biodepth)\n\n# Site:Mix denotes the random effect varies independently for each combination of levels in the Site and Mix factors\nbio.lmer3 <- lmer(Shoot2 ~ Diversity2 + (Diversity2|Site) + (1 | Site:Mix) + (1|Mix), data = biodepth)\nanova(bio.lmer2, bio.lmer3)"},{"path":"worked-example-3---complex-designs.html","id":"model-predictions","chapter":"6 Worked Example 3 - Complex Designs","heading":"6.1.1 Model predictions","text":"Q. Can observe effect partial pooling analysis?","code":"\nnested_data <- biodepth %>% \n    group_by(Site) %>% \n    nest()\n\nmodels <- map(nested_data$data, ~ lm(Shoot2 ~ Diversity2, data = .)) %>% \n    map(predict)\nbiodepth.2 <- biodepth %>% \n    mutate(fit.m = predict(bio.lmer2, re.form = NA),\n           fit.c = predict(bio.lmer2, re.form = ~(1+Diversity2|Site)),\n           fit.l = unlist(models))\n\nbiodepth.2 %>% \n    ggplot(aes(x = Diversity2, y = Shoot2, colour = Site)) +\n    geom_point(pch = 16) + \n    geom_line(aes(y = fit.l), color = \"black\")+\n    geom_line(aes(y = fit.c))+ \n    geom_line(aes(y = fit.m), colour = \"grey\",\n              linetype = \"dashed\")+\n    facet_wrap( ~ Site)+\n   coord_cartesian(ylim = c(0, 1200))+\n   theme(legend.position = \"none\")"},{"path":"reporting-mixed-model-results.html","id":"reporting-mixed-model-results","chapter":"7 Reporting Mixed Model Results","heading":"7 Reporting Mixed Model Results","text":"get model, present accurate, clear attractive form.summary() function provides us useful numbers amount variance left fitting fixed effects can assigned random effects. also provides information correlated random effects , may interest understanding structure data well.can use check modelled random effect structure matches data.includes coefficient estimates, t-statistics p-values fixed effectsWe can also produce anova() type summary fixed effectsWe may also wish report \\(R^2\\) values model fit. requires MuMIn package ((r-MuMIn?)), though later see can also produced part report package.calculates two values first \\(R^2_{m}\\) marginal \\(R^2\\) value, representing proportion variance explained fixed effects. second \\(R^2_{c}\\) conditional \\(R^2\\), proportion variance explained full model, fixed random effects.","code":"\nbio.lmer2 <- lmer(Shoot2 ~ Diversity2 + (Diversity2|Site) + (1 | Site:Mix) + (1|Mix) + (1 | Block), data = biodepth)\n\nsummary(bio.lmer2)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: Shoot2 ~ Diversity2 + (Diversity2 | Site) + (1 | Site:Mix) +  \n##     (1 | Mix) + (1 | Block)\n##    Data: biodepth\n## \n## REML criterion at convergence: 6045.1\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -2.4340 -0.4698 -0.0866  0.3430  3.5258 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev. Corr\n##  Site:Mix (Intercept) 20077.6  141.70       \n##  Mix      (Intercept) 15857.6  125.93       \n##  Block    (Intercept)   520.6   22.82       \n##  Site     (Intercept) 17106.8  130.79       \n##           Diversity2   1363.2   36.92   1.00\n##  Residual             16747.3  129.41       \n## Number of obs: 451, groups:  Site:Mix, 227; Mix, 192; Block, 15; Site, 8\n## \n## Fixed effects:\n##             Estimate Std. Error      df t value Pr(>|t|)    \n## (Intercept)  346.322     52.004   7.856   6.659 0.000173 ***\n## Diversity2    79.355     17.598   9.288   4.509 0.001357 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##            (Intr)\n## Diversity2 0.434 \n## optimizer (nloptwrap) convergence code: 0 (OK)\n## boundary (singular) fit: see help('isSingular')\nanova(bio.lmer2)\nlibrary(MuMIn)\nr.squaredGLMM(bio.lmer2)##            R2m       R2c\n## [1,] 0.1082987 0.8321128"},{"path":"reporting-mixed-model-results.html","id":"tables","chapter":"7 Reporting Mixed Model Results","heading":"7.1 Tables","text":"packages producing beautiful summary tables regression models, can handle mixed-effects models, sjPlot Lüdecke (2023b) package one robust produces simple HTML table detailing fixed random effects, produces 95% confidence intervals fixed effects calculates \\(R^2\\) values :","code":"\nsjPlot::tab_model(bio.lmer2)"},{"path":"reporting-mixed-model-results.html","id":"figures","chapter":"7 Reporting Mixed Model Results","heading":"7.2 Figures","text":"covered packages allow us easily produce marginal conditional fits, along 95% confidence prediction intervals: output ggplot2 figures, allowing plenty customisation presentation\nFigure 7.1: Scatter plot predicted yield function number species different sites experimental groups. plot showcases predicted conditional fixed effects random effects 95% prediction intervals.\n","code":"\nggpredict(bio.lmer2, terms = c(\"Diversity2\", \"Site\"), type = \"random\") %>% \nplot(., add.data = TRUE)\n# Custom colors\ncustom.col <- c(\"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\",\n                \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n\n# Create the plot with ggpredict and customization\nggpredict(bio.lmer2, terms = c(\"Diversity2\", \"Site\"), type = \"random\") %>% \n  plot(., add.data = TRUE) + \n  facet_wrap(~ group) +\n  theme(legend.position = \"none\") +\n  scale_colour_manual(values = custom.col) +  # Custom line colors\n  scale_fill_manual(values = custom.col) +  # Custom fill colors\n  labs(y = \"Yield\", \n       x = \"Number of species\",\n       title = \"\") +  # Axis and title labels\n  scale_x_continuous(breaks = c(0, 2, 4), \n                     labels = c(\"2\", \"8\", \"32\"))  # Specify x-axis breaks and labels\n# Note ggpredict codes random effects as \"groups\" with a hidden label\n\n###\n\nggpredict(bio.lmer2, terms = c(\"Diversity2\", \"Site\"), \n          type = \"random\") %>% tibble() %>% \n  head()"},{"path":"reporting-mixed-model-results.html","id":"write-ups","chapter":"7 Reporting Mixed Model Results","heading":"7.3 Write-ups","text":"Part easystats range packages (along performance) - report(Makowski et al. (2023)) phenomenally powerful package aiding write-making sure important statistics reported.however substitute logic human understanding.","code":"\nlibrary(report)\nreport(mixed_model)## We fitted a linear mixed model (estimated using REML and nloptwrap optimizer)\n## to predict y with x (formula: y ~ x). The model included group as random effect\n## (formula: ~1 | group). The model's total explanatory power is substantial\n## (conditional R2 = 0.70) and the part related to the fixed effects alone\n## (marginal R2) is of 0.10. The model's intercept, corresponding to x = 0, is at\n## 23.27 (95% CI [10.53, 36.01], t(426) = 3.59, p < .001). Within this model:\n## \n##   - The effect of x is statistically significant and positive (beta = 2.03, 95%\n## CI [1.69, 2.36], t(426) = 11.90, p < .001; Std. beta = 0.31, 95% CI [0.26,\n## 0.37])\n## \n## Standardized parameters were obtained by fitting the model on a standardized\n## version of the dataset. 95% Confidence Intervals (CIs) and p-values were\n## computed using a Wald t-distribution approximation."},{"path":"worked-example-4.html","id":"worked-example-4","chapter":"8 Worked Example 4","heading":"8 Worked Example 4","text":"microbiologist wishes know four growth media best rearing large populations anthrax, quickly. However, poorly funded scientist large enough incubator grow lots replicate populations. Instead requests space five different incubators owned , better-funded researchers. incubator just space four bottles medium. scientist allocates growth medium one bottle per incubator random, inoculates anthrax monitors population growth rate.data available :\nCan produce suitable linear mixed model analysis data,\nanswer question “four growth media best rearing\nlarge populations anthrax?”\n","code":"\nbacteria <- readRDS(\"bacteria.rds\")"},{"path":"summary.html","id":"summary","chapter":"9 Summary","heading":"9 Summary","text":"suggested workflow:Start model containing fixed effects: Begin fitting model fixed effects relevant research question. Include main predictors potential interactions hypothesize might exist. example, predictors B, might start model like response ~ + B + :B.Start model containing fixed effects: Begin fitting model fixed effects relevant research question. Include main predictors potential interactions hypothesize might exist. example, predictors B, might start model like response ~ + B + :B.Assess fixed effects interactions: Evaluate significance, direction, magnitude fixed effects coefficients. Look interactions show significant effects consider interpretation context research question. step allows identify key variables interactions important explaining variation response variable.Assess fixed effects interactions: Evaluate significance, direction, magnitude fixed effects coefficients. Look interactions show significant effects consider interpretation context research question. step allows identify key variables interactions important explaining variation response variable.Model evaluation refinement: Assess goodness fit fixed effects model using appropriate measures like AIC, BIC, model deviance. Consider conducting model comparison evaluate different models alternative fixed effects structures. process helps refine model select appropriate combination variables interactions. However - substitution carefully considered hypotheses experimental design.Model evaluation refinement: Assess goodness fit fixed effects model using appropriate measures like AIC, BIC, model deviance. Consider conducting model comparison evaluate different models alternative fixed effects structures. process helps refine model select appropriate combination variables interactions. However - substitution carefully considered hypotheses experimental design.Incorporate random effects: identified significant fixed effects relevant interactions, can consider inclusion random effects. Random effects capture variation different levels can account individual differences clustering within groups. Evaluate need random intercepts, random slopes, crossed random effects based research design nature data.Incorporate random effects: identified significant fixed effects relevant interactions, can consider inclusion random effects. Random effects capture variation different levels can account individual differences clustering within groups. Evaluate need random intercepts, random slopes, crossed random effects based research design nature data.Assess compare models random effects: Fit models random effects compare fit fixed effects model. Consider appropriate measures likelihood ratio tests, AIC, BIC model comparison. Evaluate contribution random effects model.However - substitution carefully considered hypotheses experimental design. seen examples leave random effects place despite LRT tests.Assess compare models random effects: Fit models random effects compare fit fixed effects model. Consider appropriate measures likelihood ratio tests, AIC, BIC model comparison. Evaluate contribution random effects model.However - substitution carefully considered hypotheses experimental design. seen examples leave random effects place despite LRT tests.Validate interpret final model: Validate final model assessing assumptions, checking influential observations, performing sensitivity analysis. Interpret estimated coefficients, including fixed effects random effects, context research question. Report results figures, summary tables carefully considered text summarising analysis.Validate interpret final model: Validate final model assessing assumptions, checking influential observations, performing sensitivity analysis. Interpret estimated coefficients, including fixed effects random effects, context research question. Report results figures, summary tables carefully considered text summarising analysis.initially focusing fixed effects, can establish foundation model identify significant predictors interactions. step allows better understand relationships data guide subsequent inclusion random effects appropriate.https://ademos.people.uic.edu/Chapter17.html#121_crossed__nested_designs","code":""},{"path":"summary.html","id":"mixed-model-extensions","chapter":"9 Summary","heading":"9.1 Mixed Model extensions","text":"","code":""},{"path":"summary.html","id":"practical-problems","chapter":"9 Summary","heading":"9.2 Practical problems","text":"two common issues warnings likely encounter fitting linear models:boundary (singular) fit: see help('isSingular'): model fit, generated warning random effects small, common complex mixed-effect models. can read help pageboundary (singular) fit: see help('isSingular'): model fit, generated warning random effects small, common complex mixed-effect models. can read help pageConvergence warnings: Values mixed-effects models determined using optimisation algorithms. Sometimes algorithms fail converge best parameter estimate, produce error. several possible solutions:\nNormalise rescale: Rescaling variables can mitigate issues caused differences scales magnitudes predictors, can affect optimization process. can rescale fixed effects predictors subtracting mean dividing standard deviation. centers variables around zero scales standard deviation 1. can done using scale() function R.\nTry alternative optimisation algorithms: e.g. lmer3 <- lmer(y ~ x + (x | group), data = data, control = lmerControl(optimizer =\"Nelder_Mead\"))\nFinally, although pains admit , try running model using different package - unique slightly different optimisation protocols.\nConvergence warnings: Values mixed-effects models determined using optimisation algorithms. Sometimes algorithms fail converge best parameter estimate, produce error. several possible solutions:Normalise rescale: Rescaling variables can mitigate issues caused differences scales magnitudes predictors, can affect optimization process. can rescale fixed effects predictors subtracting mean dividing standard deviation. centers variables around zero scales standard deviation 1. can done using scale() function R.Try alternative optimisation algorithms: e.g. lmer3 <- lmer(y ~ x + (x | group), data = data, control = lmerControl(optimizer =\"Nelder_Mead\"))Finally, although pains admit , try running model using different package - unique slightly different optimisation protocols.","code":""},{"path":"summary.html","id":"further-reading","chapter":"9 Summary","heading":"9.3 Further Reading","text":"essential reading continue mixed-model journey!brief introduction mixed effects modelling multi-model inference ecology Harrison et al. (2018)brief introduction mixed effects modelling multi-model inference ecology Harrison et al. (2018)Mixed Effects Models Extensions Ecology R Zuur et al. (2009)Mixed Effects Models Extensions Ecology R Zuur et al. (2009)Perils pitfalls mixed-effects regression models biology Silk et al. (2020)Perils pitfalls mixed-effects regression models biology Silk et al. (2020)","code":""},{"path":"summary.html","id":"references","chapter":"9 Summary","heading":"9.4 References","text":"","code":""}]
